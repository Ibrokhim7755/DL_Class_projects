{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms as ts\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "train_path ='D:/Data/Datasets/30vnf_Food_Images/Train'\n",
    "valid_path = 'D:/Data/Datasets/30vnf_Food_Images/Validate'\n",
    "test_path = 'D:/Data/Datasets/30vnf_Food_Images/Test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = ts.Compose([ts.Resize((128, 128)),\n",
    "                ts.ToTensor(),\n",
    "                ts.RandomRotation(degrees=15),\n",
    "                ts.RandomHorizontalFlip(),\n",
    "                ts.Normalize(0.5, 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 17581\n",
      "Validation dataset: 2515\n",
      "Test dataset: 5040\n",
      "Number of classes: 30\n"
     ]
    }
   ],
   "source": [
    "def load_data(train, test, valid):\n",
    "    \n",
    "    train = datasets.ImageFolder(root=train_path, transform=trf)\n",
    "    test = datasets.ImageFolder(root=test_path, transform=trf)\n",
    "    valid = datasets.ImageFolder(root=valid_path, transform=trf)\n",
    "\n",
    "    print(f'Train dataset: {len(train)}')\n",
    "    print(f'Validation dataset: {len(valid)}')\n",
    "    print(f'Test dataset: {len(test)}')\n",
    "    print(f'Number of classes: {len(train.classes)}')\n",
    "\n",
    "    return train, test, valid  \n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_data(train_path,test_path,valid_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n",
      "79\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataloader\n",
    "bs=64\n",
    "train_dl = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=2)\n",
    "val_dl = DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=2)\n",
    "test_dl = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=2)\n",
    "\n",
    "print(len(train_dl))\n",
    "print(len(val_dl))\n",
    "print(len(test_dl))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "im_size = 128\n",
    "in_chs = 3\n",
    "out_chs = 16\n",
    "ks = 3\n",
    "pad = 1 \n",
    "pool_size = 2\n",
    "num_classes = 30\n",
    "\n",
    "in_fs = (im_size // 32) * (im_size // 32)* out_chs\n",
    "print(in_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mynet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout2d(p=0.4, inplace=False)\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=30, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class mynet(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, in_fs, ks, pad, ps, n_cls):\n",
    "        super(mynet, self).__init__()\n",
    "        \n",
    "        self.in_chs = in_chs,\n",
    "        self.out_chs = out_chs,\n",
    "        self.in_fs = in_fs,\n",
    "        self.ks = ks,\n",
    "        self.pad = pad,\n",
    "        self.ps = ps,\n",
    "        self.n_cls = n_cls\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_chs,out_chs,kernel_size=ks,stride=ps,padding=pad)\n",
    "        self.conv2 = nn.Conv2d(out_chs,out_chs*2,kernel_size=ks,stride=ps,padding=pad)\n",
    "        self.conv3 = nn.Conv2d(out_chs*2,out_chs*4,kernel_size=ks,stride=ps,padding=pad)\n",
    "        self.conv4 = nn.Conv2d(out_chs*4,out_chs*4,kernel_size=ks,stride=ps,padding=pad)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = ps, stride = ps)\n",
    "        self.dropout = nn.Dropout2d(0.4)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=in_fs, out_features=in_fs//2 )\n",
    "        self.fc2 = nn.Linear(in_features=in_fs//2, out_features=in_fs//4)\n",
    "        self.fc3 = nn.Linear(in_features=in_fs//4, out_features=n_cls)\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(self.batchnorm2(self.pool(x)))\n",
    "        x = self.batchnorm3(self.pool(F.relu(self.conv3(x))))\n",
    "        x = self.dropout(self.conv4(x))\n",
    "        bs= x.shape[0]\n",
    "        x = x.view(bs, -1) # Flatten layer\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "m = mynet(in_chs = in_chs, out_chs = out_chs, in_fs = in_fs, ks = ks, pad = pad, ps = pool_size, n_cls = num_classes)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0311, 0.0286, 0.0404, 0.0350, 0.0366, 0.0379, 0.0363, 0.0398, 0.0425,\n",
       "         0.0306, 0.0289, 0.0312, 0.0410, 0.0404, 0.0245, 0.0302, 0.0194, 0.0241,\n",
       "         0.0336, 0.0277, 0.0384, 0.0287, 0.0414, 0.0232, 0.0256, 0.0342, 0.0413,\n",
       "         0.0441, 0.0311, 0.0323]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(1, in_chs, im_size, im_size)\n",
    "m(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(m): return m.to(\"cuda\"), 20, \"cuda\", torch.nn.CrossEntropyLoss(), torch.optim.Adam(params = m.parameters(), lr = 0.001)\n",
    "\n",
    "m, epochs, device, loss_fn, optimizer = train_setup(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:04,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train process is finished\n",
      "Epoch 1 train loss -> 3.353\n",
      "Epoch 1 train accuracy -> 0.098\n",
      "Epoch 1 validation is finished\n",
      "Epoch 1 validation loss -> 3.344\n",
      "Epoch 1  validation accuracy -> 0.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [04:25,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train process is finished\n",
      "Epoch 2 train loss -> 3.327\n",
      "Epoch 2 train accuracy -> 0.128\n",
      "Epoch 2 validation is finished\n",
      "Epoch 2 validation loss -> 3.340\n",
      "Epoch 2  validation accuracy -> 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [04:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train process is finished\n",
      "Epoch 3 train loss -> 3.333\n",
      "Epoch 3 train accuracy -> 0.124\n",
      "Epoch 3 validation is finished\n",
      "Epoch 3 validation loss -> 3.328\n",
      "Epoch 3  validation accuracy -> 0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [02:36,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train process is finished\n",
      "Epoch 4 train loss -> 3.338\n",
      "Epoch 4 train accuracy -> 0.118\n",
      "Epoch 4 validation is finished\n",
      "Epoch 4 validation loss -> 3.358\n",
      "Epoch 4  validation accuracy -> 0.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:43,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train process is finished\n",
      "Epoch 5 train loss -> 3.378\n",
      "Epoch 5 train accuracy -> 0.079\n",
      "Epoch 5 validation is finished\n",
      "Epoch 5 validation loss -> 3.396\n",
      "Epoch 5  validation accuracy -> 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [04:52,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train process is finished\n",
      "Epoch 6 train loss -> 3.396\n",
      "Epoch 6 train accuracy -> 0.061\n",
      "Epoch 6 validation is finished\n",
      "Epoch 6 validation loss -> 3.396\n",
      "Epoch 6  validation accuracy -> 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [04:37,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train process is finished\n",
      "Epoch 7 train loss -> 3.395\n",
      "Epoch 7 train accuracy -> 0.062\n",
      "Epoch 7 validation is finished\n",
      "Epoch 7 validation loss -> 3.395\n",
      "Epoch 7  validation accuracy -> 0.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:48,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train process is finished\n",
      "Epoch 8 train loss -> 3.396\n",
      "Epoch 8 train accuracy -> 0.061\n",
      "Epoch 8 validation is finished\n",
      "Epoch 8 validation loss -> 3.396\n",
      "Epoch 8  validation accuracy -> 0.061\n",
      "No improvement in validation loss for 5 epochs. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "patience = 5  \n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0\n",
    "improvement = 0\n",
    "\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch_loss, epoch_acc, total = 0, 0, 0\n",
    "    for idx, batch in tqdm(enumerate(train_dl)):\n",
    "        ims, gts = batch\n",
    "        ims, gts = ims.to(device), gts.to(device)\n",
    "        \n",
    "        total += ims.shape[0]\n",
    "        \n",
    "        preds = m(ims)\n",
    "        loss = loss_fn(preds, gts)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred_cls = torch.max(preds.data, dim = 1)\n",
    "        epoch_acc += (pred_cls == gts).sum().item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    tr_loss = epoch_loss / len(train_dl)\n",
    "    train_losses.append(tr_loss)\n",
    "    train_accs.append(epoch_acc/total)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} train process is finished\")\n",
    "    print(f\"Epoch {epoch + 1} train loss -> {(tr_loss):.3f}\")\n",
    "    print(f\"Epoch {epoch + 1} train accuracy -> {(epoch_acc / total):.3f}\")\n",
    "    \n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        val_epoch_loss, val_epoch_acc, val_total = 0, 0, 0\n",
    "        for idx, batch in enumerate(val_dl):\n",
    "            ims, gts = batch\n",
    "            ims, gts = ims.to(device), gts.to(device)\n",
    "            val_total += ims.shape[0]\n",
    "\n",
    "            \n",
    "            preds = m(ims)\n",
    "            loss = loss_fn(preds, gts)\n",
    "\n",
    "            _, pred_cls = torch.max(preds.data, dim = 1)\n",
    "            val_epoch_acc += (pred_cls == gts).sum().item()\n",
    "            val_epoch_loss += loss.item()\n",
    "        \n",
    "        val_acc = val_epoch_acc / val_total\n",
    "        val_loss = val_epoch_loss / len(val_dl)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} validation is finished\")\n",
    "        print(f\"Epoch {epoch + 1} validation loss -> {(val_loss):.3f}\")\n",
    "        print(f\"Epoch {epoch + 1}  validation accuracy -> {val_acc:.3f}\")\n",
    "        \n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "            improvement = 0\n",
    "            torch.save(m.state_dict(), 'Custom_model.pth')\n",
    "        else:\n",
    "            improvement += 1\n",
    "            if improvement >= patience:\n",
    "                print(f\"No improvement in validation loss for {patience} epochs. Stopping early.\")\n",
    "                break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on kernel_size of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3136133978.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[125], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    275it [04:41,  1.02s/it]\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "275it [04:41,  1.02s/it]\n",
    "Epoch 1 train process is finished\n",
    "Epoch 1 train loss -> 3.364\n",
    "Epoch 1 train accuracy -> 0.086\n",
    "Epoch 1 validation is finished\n",
    "Epoch 1 validation loss -> 3.355\n",
    "Epoch 1  validation accuracy -> 0.093\n",
    "275it [02:37,  1.75it/s]\n",
    "Epoch 2 train process is finished\n",
    "Epoch 2 train loss -> 3.333\n",
    "Epoch 2 train accuracy -> 0.119\n",
    "Epoch 2 validation is finished\n",
    "Epoch 2 validation loss -> 3.328\n",
    "Epoch 2  validation accuracy -> 0.123\n",
    "275it [02:35,  1.77it/s]\n",
    "Epoch 3 train process is finished\n",
    "Epoch 3 train loss -> 3.315\n",
    "Epoch 3 train accuracy -> 0.138\n",
    "Epoch 3 validation is finished\n",
    "Epoch 3 validation loss -> 3.312\n",
    "Epoch 3  validation accuracy -> 0.141\n",
    "275it [02:37,  1.75it/s]\n",
    "Epoch 4 train process is finished\n",
    "Epoch 4 train loss -> 3.297\n",
    "Epoch 4 train accuracy -> 0.157\n",
    "Epoch 4 validation is finished\n",
    "Epoch 4 validation loss -> 3.304\n",
    "Epoch 4  validation accuracy -> 0.150\n",
    "275it [02:35,  1.77it/s]\n",
    "Epoch 5 train process is finished\n",
    "Epoch 5 train loss -> 3.277\n",
    "Epoch 5 train accuracy -> 0.178\n",
    "Epoch 5 validation is finished\n",
    "Epoch 5 validation loss -> 3.274\n",
    "Epoch 5  validation accuracy -> 0.182\n",
    "275it [02:33,  1.79it/s]\n",
    "Epoch 6 train process is finished\n",
    "Epoch 6 train loss -> 3.268\n",
    "Epoch 6 train accuracy -> 0.188\n",
    "Epoch 6 validation is finished\n",
    "Epoch 6 validation loss -> 3.271\n",
    "Epoch 6  validation accuracy -> 0.183\n",
    "275it [29:16,  6.39s/it] \n",
    "Epoch 7 train process is finished\n",
    "Epoch 7 train loss -> 3.265\n",
    "Epoch 7 train accuracy -> 0.190\n",
    "Epoch 7 validation is finished\n",
    "Epoch 7 validation loss -> 3.265\n",
    "Epoch 7  validation accuracy -> 0.190\n",
    "275it [02:33,  1.79it/s]\n",
    "Epoch 8 train process is finished\n",
    "Epoch 8 train loss -> 3.256\n",
    "Epoch 8 train accuracy -> 0.199\n",
    "Epoch 8 validation is finished\n",
    "Epoch 8 validation loss -> 3.263\n",
    "Epoch 8  validation accuracy -> 0.194\n",
    "275it [02:36,  1.76it/s]\n",
    "Epoch 9 train process is finished\n",
    "Epoch 9 train loss -> 3.249\n",
    "Epoch 9 train accuracy -> 0.205\n",
    "Epoch 9 validation is finished\n",
    "Epoch 9 validation loss -> 3.265\n",
    "Epoch 9  validation accuracy -> 0.190\n",
    "275it [04:20,  1.06it/s]\n",
    "Epoch 10 train process is finished\n",
    "Epoch 10 train loss -> 3.249\n",
    "Epoch 10 train accuracy -> 0.206\n",
    "Epoch 10 validation is finished\n",
    "Epoch 10 validation loss -> 3.268\n",
    "Epoch 10  validation accuracy -> 0.187\n",
    "275it [03:53,  1.18it/s]\n",
    "Epoch 11 train process is finished\n",
    "Epoch 11 train loss -> 3.248\n",
    "Epoch 11 train accuracy -> 0.207\n",
    "Epoch 11 validation is finished\n",
    "Epoch 11 validation loss -> 3.265\n",
    "Epoch 11  validation accuracy -> 0.192\n",
    "275it [03:31,  1.30it/s]\n",
    "Epoch 12 train process is finished\n",
    "Epoch 12 train loss -> 3.248\n",
    "Epoch 12 train accuracy -> 0.207\n",
    "Epoch 12 validation is finished\n",
    "Epoch 12 validation loss -> 3.265\n",
    "Epoch 12  validation accuracy -> 0.191\n",
    "No improvement in validation loss for 4 epochs. Stopping early.\n",
    "Train dataset: 17581\n",
    "Valid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on kernel_size of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "275it [03:54,  1.17it/s]\n",
    "Epoch 1 train process is finished\n",
    "Epoch 1 train loss -> 3.361\n",
    "Epoch 1 train accuracy -> 0.094\n",
    "Epoch 1 validation is finished\n",
    "Epoch 1 validation loss -> 3.343\n",
    "Epoch 1  validation accuracy -> 0.112\n",
    "275it [03:58,  1.15it/s]\n",
    "Epoch 2 train process is finished\n",
    "Epoch 2 train loss -> 3.357\n",
    "Epoch 2 train accuracy -> 0.100\n",
    "Epoch 2 validation is finished\n",
    "Epoch 2 validation loss -> 3.360\n",
    "Epoch 2  validation accuracy -> 0.097\n",
    "275it [03:05,  1.49it/s]\n",
    "Epoch 3 train process is finished\n",
    "Epoch 3 train loss -> 3.347\n",
    "Epoch 3 train accuracy -> 0.109\n",
    "Epoch 3 validation is finished\n",
    "Epoch 3 validation loss -> 3.380\n",
    "Epoch 3  validation accuracy -> 0.076\n",
    "275it [05:12,  1.14s/it]\n",
    "Epoch 4 train process is finished\n",
    "Epoch 4 train loss -> 3.350\n",
    "Epoch 4 train accuracy -> 0.106\n",
    "Epoch 4 validation is finished\n",
    "Epoch 4 validation loss -> 3.351\n",
    "Epoch 4  validation accuracy -> 0.105\n",
    "275it [05:10,  1.13s/it]\n",
    "Epoch 5 train process is finished\n",
    "Epoch 5 train loss -> 3.347\n",
    "Epoch 5 train accuracy -> 0.108\n",
    "Epoch 5 validation is finished\n",
    "Epoch 5 validation loss -> 3.349\n",
    "Epoch 5  validation accuracy -> 0.107\n",
    "275it [03:18,  1.39it/s]\n",
    "Epoch 6 train process is finished\n",
    "Epoch 6 train loss -> 3.342\n",
    "Epoch 6 train accuracy -> 0.114\n",
    "Epoch 6 validation is finished\n",
    "Epoch 6 validation loss -> 3.358\n",
    "Epoch 6  validation accuracy -> 0.099\n",
    "No improvement in validation loss for 5 epochs. Stopping early.\n",
    "  Cell In[45], line 1\n",
    "    275it [04:41,  1.02s/it]\n",
    "      ^\n",
    "SyntaxError: invalid decimal literal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
